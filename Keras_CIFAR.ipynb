{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras - CIFAR.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbCEdHpTvSEg",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sodO__L0cNAd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "outputId": "a5c064bb-8479-4a5b-f34f-b793d4d0357f"
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "# List of names for each CIFAR10 class\n",
        "cifar10_class_names = {\n",
        "    0: \"Plane\",\n",
        "    1: \"Car\",\n",
        "    2: \"Bird\",\n",
        "    3: \"Cat\",\n",
        "    4: \"Deer\",\n",
        "    5: \"Dog\",\n",
        "    6: \"Frog\",\n",
        "    7: \"Horse\",\n",
        "    8: \"Boat\",\n",
        "    9: \"Truck\"\n",
        "}\n",
        "\n",
        "# Load the entire data set\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Loop through each picture in the data set\n",
        "for i in range(2):\n",
        "    # Grab an image from the data set\n",
        "    sample_image = x_train[i]\n",
        "    # Grab the image's expected class id\n",
        "    image_class_number = y_train[i][0]\n",
        "    # Look up the class name from the class id\n",
        "    image_class_name = cifar10_class_names[image_class_number]\n",
        "\n",
        "    # Draw the image as a plot\n",
        "    plt.imshow(sample_image)\n",
        "    # Label the image\n",
        "    plt.title(image_class_name)\n",
        "    # Show the plot on the screen\n",
        "    plt.show()\n",
        "\n",
        "# applying transformation to image\n",
        "train_gen = ImageDataGenerator(rotation_range=45, \n",
        "                               width_shift_range=0.1, \n",
        "                               shear_range=0.3, \n",
        "                               height_shift_range=0.1, \n",
        "                               zoom_range=0.1,\n",
        "                               horizontal_flip=True)\n",
        "# test_gen = ImageDataGenerator()\n",
        "train_gen.fit(x_train)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GoW0-gEcRDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Activation\n",
        "from pathlib import Path\n",
        "\n",
        "# Load data set\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Normalize data set to 0-to-1 range\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "# Convert class vectors to binary class matrices\n",
        "# Our labels are single values from 0 to 9.\n",
        "# Instead, we want each label to be an array with on element set to 1 and and the rest set to 0.\n",
        "y_train = keras.utils.to_categorical(y_train, 10)\n",
        "y_test = keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "training_set= train_gen.flow(x_train, y_train, batch_size=128)\n",
        "test_set= train_gen.flow(x_test, y_test, batch_size=128)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "585whLqPdXMa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "80355b16-6179-4ca6-8253-9fd45bb572b3"
      },
      "source": [
        "# Create a model and add layers\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), input_shape=(32, 32, 3)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, kernel_size=(3, 3)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=(3, 3)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, kernel_size=(3, 3)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=(3, 3)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, kernel_size=(3, 3)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Conv2D(256, kernel_size=(3, 3)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# model.add(Conv2D(32, kernel_size=(3, 3), input_shape=(32, 32, 3)))\n",
        "# model.add(LeakyReLU(alpha=0.05))\n",
        "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# model.add(Dropout(0.25))\n",
        "\n",
        "# model.add(Conv2D(64, kernel_size=(3, 3)))\n",
        "# model.add(LeakyReLU(alpha=0.05))\n",
        "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# model.add(Dropout(0.25))\n",
        "\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(256))\n",
        "\n",
        "# model.add(LeakyReLU(alpha=0.05))\n",
        "# model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# model.add(Conv2D(32, kernel_size=(3, 3), input_shape =(32, 32, 3)))\n",
        "# model.add(LeakyReLU(alpha=0.05))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# model.add(Dropout(0.25))\n",
        "\n",
        "# model.add(Conv2D(64, kernel_size=(3, 3)))\n",
        "# model.add(LeakyReLU(alpha=0.05))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# model.add(Dropout(0.25))\n",
        "\n",
        "# model.add(Conv2D(128, kernel_size=(3, 3)))\n",
        "# model.add(LeakyReLU(alpha=0.05))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# model.add(Dropout(0.25))\n",
        "\n",
        "# model.add(Flatten())\n",
        "# model.add(Dropout(0.25))\n",
        "# model.add(Dense(128))\n",
        "# model.add(LeakyReLU(alpha=0.1))\n",
        "\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Dropout(0.4))\n",
        "# model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Print a summary of the model\n",
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 30, 30, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 30, 30, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 28, 28, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 28, 28, 32)        128       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 26, 26, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 26, 26, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 26, 26, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 24, 24, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 24, 24, 64)        256       \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 22, 22, 128)       73856     \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 22, 22, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 22, 22, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 20, 20, 128)       147584    \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 20, 20, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 20, 20, 128)       512       \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 20, 20, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 18, 18, 256)       295168    \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 18, 18, 256)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 18, 18, 256)       1024      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 18, 18, 256)       0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 82944)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                829450    \n",
            "=================================================================\n",
            "Total params: 1,414,442\n",
            "Trainable params: 1,413,034\n",
            "Non-trainable params: 1,408\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AjnumEleBoC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    \n",
        "    optimizer=tf.keras.optimizers.RMSprop(\n",
        "        learning_rate=0.001,\n",
        "        rho=0.9,\n",
        "        momentum=0.9,\n",
        "        epsilon=1e-07,\n",
        "        centered=False,\n",
        "        name=\"RMSprop\",\n",
        "    ),\n",
        "    \n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSkF8tVtqSzR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8fa229ce-7cc0-4c11-c3bc-b8642c2deee9"
      },
      "source": [
        "# Train the model\n",
        "with tf.device('/device:GPU:0'):\n",
        "  model.fit(\n",
        "      training_set,\n",
        "      epochs=200,\n",
        "      validation_data=test_set,\n",
        "      verbose=1,\n",
        "      shuffle=True\n",
        "  )"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "391/391 [==============================] - 55s 141ms/step - loss: 14.0273 - accuracy: 0.1963 - val_loss: 9.3475 - val_accuracy: 0.1077\n",
            "Epoch 2/200\n",
            "391/391 [==============================] - 45s 116ms/step - loss: 1.9677 - accuracy: 0.2976 - val_loss: 2.6121 - val_accuracy: 0.2353\n",
            "Epoch 3/200\n",
            "391/391 [==============================] - 45s 115ms/step - loss: 2.0400 - accuracy: 0.3097 - val_loss: 1.2146 - val_accuracy: 0.3176\n",
            "Epoch 4/200\n",
            "391/391 [==============================] - 45s 116ms/step - loss: 1.9051 - accuracy: 0.3321 - val_loss: 1.6630 - val_accuracy: 0.3372\n",
            "Epoch 5/200\n",
            "391/391 [==============================] - 45s 115ms/step - loss: 1.7796 - accuracy: 0.3687 - val_loss: 1.6883 - val_accuracy: 0.3587\n",
            "Epoch 6/200\n",
            "391/391 [==============================] - 45s 116ms/step - loss: 1.6932 - accuracy: 0.4024 - val_loss: 1.7130 - val_accuracy: 0.3866\n",
            "Epoch 7/200\n",
            "391/391 [==============================] - 46s 117ms/step - loss: 1.6446 - accuracy: 0.4238 - val_loss: 2.2411 - val_accuracy: 0.3606\n",
            "Epoch 8/200\n",
            "391/391 [==============================] - 45s 116ms/step - loss: 1.6034 - accuracy: 0.4445 - val_loss: 1.1635 - val_accuracy: 0.3884\n",
            "Epoch 9/200\n",
            "391/391 [==============================] - 45s 116ms/step - loss: 1.5561 - accuracy: 0.4655 - val_loss: 1.3524 - val_accuracy: 0.4052\n",
            "Epoch 10/200\n",
            "391/391 [==============================] - 45s 116ms/step - loss: 1.5012 - accuracy: 0.4841 - val_loss: 2.8103 - val_accuracy: 0.3886\n",
            "Epoch 11/200\n",
            "391/391 [==============================] - 45s 116ms/step - loss: 1.5090 - accuracy: 0.4907 - val_loss: 1.3453 - val_accuracy: 0.4633\n",
            "Epoch 12/200\n",
            "391/391 [==============================] - 46s 117ms/step - loss: 1.4624 - accuracy: 0.5029 - val_loss: 2.9807 - val_accuracy: 0.2976\n",
            "Epoch 13/200\n",
            "391/391 [==============================] - 46s 117ms/step - loss: 1.4456 - accuracy: 0.5116 - val_loss: 1.6349 - val_accuracy: 0.4251\n",
            "Epoch 14/200\n",
            "391/391 [==============================] - 46s 117ms/step - loss: 1.4225 - accuracy: 0.5225 - val_loss: 1.4044 - val_accuracy: 0.5292\n",
            "Epoch 15/200\n",
            "391/391 [==============================] - 46s 116ms/step - loss: 1.4371 - accuracy: 0.5235 - val_loss: 1.9871 - val_accuracy: 0.4441\n",
            "Epoch 16/200\n",
            "391/391 [==============================] - 46s 117ms/step - loss: 1.4023 - accuracy: 0.5329 - val_loss: 1.4518 - val_accuracy: 0.5215\n",
            "Epoch 17/200\n",
            "391/391 [==============================] - 45s 116ms/step - loss: 1.3798 - accuracy: 0.5411 - val_loss: 1.4060 - val_accuracy: 0.5351\n",
            "Epoch 18/200\n",
            "391/391 [==============================] - 45s 116ms/step - loss: 1.3607 - accuracy: 0.5487 - val_loss: 1.8535 - val_accuracy: 0.4644\n",
            "Epoch 19/200\n",
            "391/391 [==============================] - 45s 116ms/step - loss: 1.3706 - accuracy: 0.5485 - val_loss: 2.5791 - val_accuracy: 0.3601\n",
            "Epoch 20/200\n",
            "391/391 [==============================] - 45s 115ms/step - loss: 1.3609 - accuracy: 0.5518 - val_loss: 1.8603 - val_accuracy: 0.5622\n",
            "Epoch 21/200\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.3464 - accuracy: 0.5579 - val_loss: 1.1325 - val_accuracy: 0.5680\n",
            "Epoch 22/200\n",
            "391/391 [==============================] - 45s 115ms/step - loss: 1.3057 - accuracy: 0.5677 - val_loss: 1.9287 - val_accuracy: 0.5256\n",
            "Epoch 23/200\n",
            "391/391 [==============================] - 44s 112ms/step - loss: 1.3342 - accuracy: 0.5652 - val_loss: 1.2112 - val_accuracy: 0.5524\n",
            "Epoch 24/200\n",
            "391/391 [==============================] - 43s 111ms/step - loss: 1.3159 - accuracy: 0.5716 - val_loss: 1.2478 - val_accuracy: 0.4714\n",
            "Epoch 25/200\n",
            "391/391 [==============================] - 43s 111ms/step - loss: 1.3216 - accuracy: 0.5723 - val_loss: 1.3260 - val_accuracy: 0.5873\n",
            "Epoch 26/200\n",
            "391/391 [==============================] - 43s 111ms/step - loss: 1.3042 - accuracy: 0.5787 - val_loss: 1.8343 - val_accuracy: 0.5615\n",
            "Epoch 27/200\n",
            "391/391 [==============================] - 43s 111ms/step - loss: 1.3798 - accuracy: 0.5682 - val_loss: 1.2199 - val_accuracy: 0.5882\n",
            "Epoch 28/200\n",
            "391/391 [==============================] - 43s 110ms/step - loss: 1.3133 - accuracy: 0.5789 - val_loss: 1.8385 - val_accuracy: 0.5274\n",
            "Epoch 29/200\n",
            "391/391 [==============================] - 43s 110ms/step - loss: 1.2782 - accuracy: 0.5844 - val_loss: 1.4291 - val_accuracy: 0.5479\n",
            "Epoch 30/200\n",
            "391/391 [==============================] - 43s 111ms/step - loss: 1.2718 - accuracy: 0.5892 - val_loss: 0.5988 - val_accuracy: 0.5504\n",
            "Epoch 31/200\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.2831 - accuracy: 0.5890 - val_loss: 0.7926 - val_accuracy: 0.6240\n",
            "Epoch 32/200\n",
            "391/391 [==============================] - 44s 114ms/step - loss: 1.2636 - accuracy: 0.5948 - val_loss: 1.0642 - val_accuracy: 0.5965\n",
            "Epoch 33/200\n",
            "391/391 [==============================] - 44s 114ms/step - loss: 1.2438 - accuracy: 0.5993 - val_loss: 1.0703 - val_accuracy: 0.5450\n",
            "Epoch 34/200\n",
            "391/391 [==============================] - 44s 112ms/step - loss: 1.2547 - accuracy: 0.5981 - val_loss: 0.6888 - val_accuracy: 0.5876\n",
            "Epoch 35/200\n",
            "391/391 [==============================] - 44s 112ms/step - loss: 1.2433 - accuracy: 0.6063 - val_loss: 1.1837 - val_accuracy: 0.6464\n",
            "Epoch 36/200\n",
            "391/391 [==============================] - 44s 112ms/step - loss: 1.2374 - accuracy: 0.6079 - val_loss: 1.1725 - val_accuracy: 0.5368\n",
            "Epoch 37/200\n",
            "391/391 [==============================] - 44s 112ms/step - loss: 1.2257 - accuracy: 0.6094 - val_loss: 0.6443 - val_accuracy: 0.6520\n",
            "Epoch 38/200\n",
            "391/391 [==============================] - 44s 112ms/step - loss: 1.2145 - accuracy: 0.6120 - val_loss: 1.8844 - val_accuracy: 0.5453\n",
            "Epoch 39/200\n",
            "391/391 [==============================] - 44s 111ms/step - loss: 1.2329 - accuracy: 0.6150 - val_loss: 0.6275 - val_accuracy: 0.6196\n",
            "Epoch 40/200\n",
            "391/391 [==============================] - 45s 115ms/step - loss: 1.2207 - accuracy: 0.6154 - val_loss: 1.4526 - val_accuracy: 0.6484\n",
            "Epoch 41/200\n",
            "391/391 [==============================] - 45s 114ms/step - loss: 1.2499 - accuracy: 0.6146 - val_loss: 0.7240 - val_accuracy: 0.5957\n",
            "Epoch 42/200\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.2286 - accuracy: 0.6166 - val_loss: 0.8132 - val_accuracy: 0.6187\n",
            "Epoch 43/200\n",
            "391/391 [==============================] - 44s 112ms/step - loss: 1.2025 - accuracy: 0.6222 - val_loss: 1.9770 - val_accuracy: 0.6047\n",
            "Epoch 44/200\n",
            "391/391 [==============================] - 44s 114ms/step - loss: 1.1904 - accuracy: 0.6269 - val_loss: 1.1908 - val_accuracy: 0.6525\n",
            "Epoch 45/200\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.1951 - accuracy: 0.6239 - val_loss: 1.1230 - val_accuracy: 0.6061\n",
            "Epoch 46/200\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.1931 - accuracy: 0.6275 - val_loss: 1.6068 - val_accuracy: 0.6309\n",
            "Epoch 47/200\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.2053 - accuracy: 0.6293 - val_loss: 0.7139 - val_accuracy: 0.6418\n",
            "Epoch 48/200\n",
            "391/391 [==============================] - 44s 112ms/step - loss: 1.1986 - accuracy: 0.6319 - val_loss: 1.6416 - val_accuracy: 0.5983\n",
            "Epoch 49/200\n",
            "391/391 [==============================] - 44s 112ms/step - loss: 1.1815 - accuracy: 0.6353 - val_loss: 0.7096 - val_accuracy: 0.6538\n",
            "Epoch 50/200\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.1933 - accuracy: 0.6335 - val_loss: 0.7425 - val_accuracy: 0.6159\n",
            "Epoch 51/200\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.1894 - accuracy: 0.6336 - val_loss: 1.9839 - val_accuracy: 0.5453\n",
            "Epoch 52/200\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.1882 - accuracy: 0.6386 - val_loss: 0.9958 - val_accuracy: 0.6010\n",
            "Epoch 53/200\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.1679 - accuracy: 0.6431 - val_loss: 0.6546 - val_accuracy: 0.5628\n",
            "Epoch 54/200\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.1644 - accuracy: 0.6434 - val_loss: 1.7375 - val_accuracy: 0.6556\n",
            "Epoch 55/200\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.1707 - accuracy: 0.6420 - val_loss: 0.5376 - val_accuracy: 0.6339\n",
            "Epoch 56/200\n",
            "391/391 [==============================] - 44s 112ms/step - loss: 1.1660 - accuracy: 0.6466 - val_loss: 0.6260 - val_accuracy: 0.6286\n",
            "Epoch 57/200\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.1876 - accuracy: 0.6423 - val_loss: 1.9140 - val_accuracy: 0.6318\n",
            "Epoch 58/200\n",
            "391/391 [==============================] - 44s 114ms/step - loss: 1.1610 - accuracy: 0.6487 - val_loss: 2.0738 - val_accuracy: 0.6284\n",
            "Epoch 59/200\n",
            "391/391 [==============================] - 45s 114ms/step - loss: 1.1374 - accuracy: 0.6523 - val_loss: 1.4098 - val_accuracy: 0.6600\n",
            "Epoch 60/200\n",
            "391/391 [==============================] - 45s 114ms/step - loss: 1.1408 - accuracy: 0.6545 - val_loss: 2.0542 - val_accuracy: 0.6620\n",
            "Epoch 61/200\n",
            "391/391 [==============================] - 45s 115ms/step - loss: 1.1535 - accuracy: 0.6511 - val_loss: 0.8039 - val_accuracy: 0.6828\n",
            "Epoch 62/200\n",
            "391/391 [==============================] - 45s 114ms/step - loss: 1.1489 - accuracy: 0.6535 - val_loss: 1.3542 - val_accuracy: 0.6769\n",
            "Epoch 63/200\n",
            "391/391 [==============================] - 45s 114ms/step - loss: 1.1387 - accuracy: 0.6545 - val_loss: 1.3050 - val_accuracy: 0.6386\n",
            "Epoch 64/200\n",
            "391/391 [==============================] - 45s 114ms/step - loss: 1.1647 - accuracy: 0.6542 - val_loss: 0.7238 - val_accuracy: 0.7024\n",
            "Epoch 65/200\n",
            "391/391 [==============================] - 45s 114ms/step - loss: 1.1430 - accuracy: 0.6573 - val_loss: 1.4394 - val_accuracy: 0.6079\n",
            "Epoch 66/200\n",
            "391/391 [==============================] - 45s 114ms/step - loss: 1.1428 - accuracy: 0.6586 - val_loss: 0.5021 - val_accuracy: 0.6997\n",
            "Epoch 67/200\n",
            "391/391 [==============================] - 45s 114ms/step - loss: 1.1912 - accuracy: 0.6576 - val_loss: 1.1101 - val_accuracy: 0.6148\n",
            "Epoch 68/200\n",
            "391/391 [==============================] - 45s 114ms/step - loss: 1.1553 - accuracy: 0.6572 - val_loss: 0.9976 - val_accuracy: 0.6674\n",
            "Epoch 69/200\n",
            "391/391 [==============================] - 45s 114ms/step - loss: 1.1488 - accuracy: 0.6592 - val_loss: 0.8635 - val_accuracy: 0.6599\n",
            "Epoch 70/200\n",
            "391/391 [==============================] - 45s 114ms/step - loss: 1.1457 - accuracy: 0.6592 - val_loss: 1.1151 - val_accuracy: 0.6708\n",
            "Epoch 71/200\n",
            "391/391 [==============================] - 45s 114ms/step - loss: 1.1505 - accuracy: 0.6644 - val_loss: 0.7668 - val_accuracy: 0.6871\n",
            "Epoch 72/200\n",
            "391/391 [==============================] - 45s 114ms/step - loss: 1.1179 - accuracy: 0.6624 - val_loss: 0.8182 - val_accuracy: 0.6812\n",
            "Epoch 73/200\n",
            "391/391 [==============================] - 45s 114ms/step - loss: 1.1479 - accuracy: 0.6641 - val_loss: 0.4942 - val_accuracy: 0.6835\n",
            "Epoch 74/200\n",
            "391/391 [==============================] - 45s 114ms/step - loss: 1.1213 - accuracy: 0.6669 - val_loss: 0.8512 - val_accuracy: 0.6764\n",
            "Epoch 75/200\n",
            "391/391 [==============================] - 45s 115ms/step - loss: 1.1312 - accuracy: 0.6656 - val_loss: 2.0603 - val_accuracy: 0.6405\n",
            "Epoch 76/200\n",
            "391/391 [==============================] - 45s 114ms/step - loss: 1.1099 - accuracy: 0.6697 - val_loss: 1.0496 - val_accuracy: 0.7009\n",
            "Epoch 77/200\n",
            "391/391 [==============================] - 44s 114ms/step - loss: 1.1457 - accuracy: 0.6631 - val_loss: 0.9488 - val_accuracy: 0.7020\n",
            "Epoch 78/200\n",
            "391/391 [==============================] - 45s 114ms/step - loss: 1.1179 - accuracy: 0.6700 - val_loss: 1.2138 - val_accuracy: 0.6782\n",
            "Epoch 79/200\n",
            "391/391 [==============================] - 45s 114ms/step - loss: 1.1411 - accuracy: 0.6677 - val_loss: 1.1716 - val_accuracy: 0.6906\n",
            "Epoch 80/200\n",
            "391/391 [==============================] - 45s 115ms/step - loss: 1.1331 - accuracy: 0.6698 - val_loss: 0.4219 - val_accuracy: 0.6895\n",
            "Epoch 81/200\n",
            "391/391 [==============================] - 45s 114ms/step - loss: 1.1396 - accuracy: 0.6692 - val_loss: 0.7914 - val_accuracy: 0.6831\n",
            "Epoch 82/200\n",
            "391/391 [==============================] - 45s 115ms/step - loss: 1.1164 - accuracy: 0.6734 - val_loss: 0.8922 - val_accuracy: 0.6631\n",
            "Epoch 83/200\n",
            "391/391 [==============================] - 45s 114ms/step - loss: 1.1165 - accuracy: 0.6721 - val_loss: 1.8149 - val_accuracy: 0.6667\n",
            "Epoch 84/200\n",
            "391/391 [==============================] - 44s 114ms/step - loss: 1.1362 - accuracy: 0.6716 - val_loss: 1.3327 - val_accuracy: 0.6919\n",
            "Epoch 85/200\n",
            "391/391 [==============================] - 44s 114ms/step - loss: 1.1382 - accuracy: 0.6677 - val_loss: 2.0633 - val_accuracy: 0.6456\n",
            "Epoch 86/200\n",
            "391/391 [==============================] - 45s 114ms/step - loss: 1.1246 - accuracy: 0.6749 - val_loss: 1.1234 - val_accuracy: 0.6854\n",
            "Epoch 87/200\n",
            "391/391 [==============================] - 45s 115ms/step - loss: 1.1090 - accuracy: 0.6788 - val_loss: 0.4780 - val_accuracy: 0.6658\n",
            "Epoch 88/200\n",
            "391/391 [==============================] - 44s 114ms/step - loss: 1.1163 - accuracy: 0.6759 - val_loss: 0.8987 - val_accuracy: 0.6890\n",
            "Epoch 89/200\n",
            "391/391 [==============================] - 45s 114ms/step - loss: 1.1213 - accuracy: 0.6771 - val_loss: 0.9319 - val_accuracy: 0.6962\n",
            "Epoch 90/200\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.1427 - accuracy: 0.6748 - val_loss: 1.4751 - val_accuracy: 0.6728\n",
            "Epoch 91/200\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.1081 - accuracy: 0.6756 - val_loss: 0.8276 - val_accuracy: 0.6633\n",
            "Epoch 92/200\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.1191 - accuracy: 0.6786 - val_loss: 0.7755 - val_accuracy: 0.7223\n",
            "Epoch 93/200\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.1043 - accuracy: 0.6790 - val_loss: 0.1526 - val_accuracy: 0.7024\n",
            "Epoch 94/200\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.1030 - accuracy: 0.6804 - val_loss: 1.8645 - val_accuracy: 0.6929\n",
            "Epoch 95/200\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0913 - accuracy: 0.6815 - val_loss: 0.3280 - val_accuracy: 0.6639\n",
            "Epoch 96/200\n",
            "391/391 [==============================] - 44s 114ms/step - loss: 1.1102 - accuracy: 0.6789 - val_loss: 1.3078 - val_accuracy: 0.6692\n",
            "Epoch 97/200\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.1041 - accuracy: 0.6826 - val_loss: 0.3781 - val_accuracy: 0.7281\n",
            "Epoch 98/200\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.1124 - accuracy: 0.6822 - val_loss: 1.8530 - val_accuracy: 0.6898\n",
            "Epoch 99/200\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.1431 - accuracy: 0.6813 - val_loss: 2.0523 - val_accuracy: 0.6905\n",
            "Epoch 100/200\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0757 - accuracy: 0.6880 - val_loss: 0.7189 - val_accuracy: 0.6850\n",
            "Epoch 101/200\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.1061 - accuracy: 0.6825 - val_loss: 1.5709 - val_accuracy: 0.7052\n",
            "Epoch 102/200\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0976 - accuracy: 0.6890 - val_loss: 0.8173 - val_accuracy: 0.6938\n",
            "Epoch 103/200\n",
            "391/391 [==============================] - 45s 114ms/step - loss: 1.0899 - accuracy: 0.6886 - val_loss: 0.9102 - val_accuracy: 0.7015\n",
            "Epoch 104/200\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.1036 - accuracy: 0.6870 - val_loss: 0.0386 - val_accuracy: 0.7052\n",
            "Epoch 105/200\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.1046 - accuracy: 0.6895 - val_loss: 0.2284 - val_accuracy: 0.6706\n",
            "Epoch 106/200\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.1040 - accuracy: 0.6889 - val_loss: 1.5066 - val_accuracy: 0.6579\n",
            "Epoch 107/200\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.1022 - accuracy: 0.6885 - val_loss: 1.9554 - val_accuracy: 0.6765\n",
            "Epoch 108/200\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.1173 - accuracy: 0.6868 - val_loss: 0.7301 - val_accuracy: 0.7118\n",
            "Epoch 109/200\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0991 - accuracy: 0.6887 - val_loss: 1.8885 - val_accuracy: 0.7041\n",
            "Epoch 110/200\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.1219 - accuracy: 0.6863 - val_loss: 0.4264 - val_accuracy: 0.7172\n",
            "Epoch 111/200\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0992 - accuracy: 0.6907 - val_loss: 0.9366 - val_accuracy: 0.7303\n",
            "Epoch 112/200\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0881 - accuracy: 0.6946 - val_loss: 1.4284 - val_accuracy: 0.6763\n",
            "Epoch 113/200\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0891 - accuracy: 0.6915 - val_loss: 0.4616 - val_accuracy: 0.7189\n",
            "Epoch 114/200\n",
            "391/391 [==============================] - 44s 114ms/step - loss: 1.0775 - accuracy: 0.6915 - val_loss: 0.4128 - val_accuracy: 0.7298\n",
            "Epoch 115/200\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.1148 - accuracy: 0.6929 - val_loss: 0.8076 - val_accuracy: 0.7102\n",
            "Epoch 116/200\n",
            "391/391 [==============================] - 44s 114ms/step - loss: 1.0894 - accuracy: 0.6961 - val_loss: 2.0220 - val_accuracy: 0.7129\n",
            "Epoch 117/200\n",
            "391/391 [==============================] - 44s 114ms/step - loss: 1.0870 - accuracy: 0.6952 - val_loss: 2.2059 - val_accuracy: 0.6945\n",
            "Epoch 118/200\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.1094 - accuracy: 0.6917 - val_loss: 1.8616 - val_accuracy: 0.7098\n",
            "Epoch 119/200\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0750 - accuracy: 0.6973 - val_loss: 1.1018 - val_accuracy: 0.7299\n",
            "Epoch 120/200\n",
            "391/391 [==============================] - 44s 114ms/step - loss: 1.0783 - accuracy: 0.6964 - val_loss: 1.5110 - val_accuracy: 0.6877\n",
            "Epoch 121/200\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0748 - accuracy: 0.6952 - val_loss: 1.8719 - val_accuracy: 0.7090\n",
            "Epoch 122/200\n",
            "391/391 [==============================] - 44s 114ms/step - loss: 1.0632 - accuracy: 0.7006 - val_loss: 0.7735 - val_accuracy: 0.7147\n",
            "Epoch 123/200\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0832 - accuracy: 0.6994 - val_loss: 0.6402 - val_accuracy: 0.6566\n",
            "Epoch 124/200\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0855 - accuracy: 0.6995 - val_loss: 0.8515 - val_accuracy: 0.7228\n",
            "Epoch 125/200\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0885 - accuracy: 0.6975 - val_loss: 1.8616 - val_accuracy: 0.6130\n",
            "Epoch 126/200\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0775 - accuracy: 0.7003 - val_loss: 0.6877 - val_accuracy: 0.6721\n",
            "Epoch 127/200\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0922 - accuracy: 0.6964 - val_loss: 1.6232 - val_accuracy: 0.6584\n",
            "Epoch 128/200\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0778 - accuracy: 0.6985 - val_loss: 1.4341 - val_accuracy: 0.7309\n",
            "Epoch 129/200\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0765 - accuracy: 0.6987 - val_loss: 0.7078 - val_accuracy: 0.7272\n",
            "Epoch 130/200\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0661 - accuracy: 0.7012 - val_loss: 0.5311 - val_accuracy: 0.7458\n",
            "Epoch 131/200\n",
            "391/391 [==============================] - 45s 114ms/step - loss: 1.0641 - accuracy: 0.7021 - val_loss: 1.1573 - val_accuracy: 0.6781\n",
            "Epoch 132/200\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0872 - accuracy: 0.7001 - val_loss: 0.4791 - val_accuracy: 0.7480\n",
            "Epoch 133/200\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.1093 - accuracy: 0.6978 - val_loss: 0.4693 - val_accuracy: 0.7431\n",
            "Epoch 134/200\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0838 - accuracy: 0.7039 - val_loss: 0.8903 - val_accuracy: 0.6881\n",
            "Epoch 135/200\n",
            "391/391 [==============================] - 44s 112ms/step - loss: 1.0553 - accuracy: 0.7061 - val_loss: 3.2617 - val_accuracy: 0.7022\n",
            "Epoch 136/200\n",
            "391/391 [==============================] - 44s 112ms/step - loss: 1.0761 - accuracy: 0.7042 - val_loss: 1.0637 - val_accuracy: 0.7430\n",
            "Epoch 137/200\n",
            "391/391 [==============================] - 44s 111ms/step - loss: 1.0511 - accuracy: 0.7028 - val_loss: 0.7116 - val_accuracy: 0.7241\n",
            "Epoch 138/200\n",
            "391/391 [==============================] - 45s 114ms/step - loss: 1.0871 - accuracy: 0.7048 - val_loss: 1.0957 - val_accuracy: 0.6735\n",
            "Epoch 139/200\n",
            "391/391 [==============================] - 45s 114ms/step - loss: 1.0877 - accuracy: 0.7027 - val_loss: 0.8740 - val_accuracy: 0.6889\n",
            "Epoch 140/200\n",
            "329/391 [========================>.....] - ETA: 6s - loss: 1.0438 - accuracy: 0.7082Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPxr2Vog9WOj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e275c578-9778-4b90-c6a2-691e0982abae"
      },
      "source": [
        "# Train the model\n",
        "with tf.device('/device:GPU:0'):\n",
        "  model.fit(\n",
        "      training_set,\n",
        "      epochs=50,\n",
        "      validation_data=test_set,\n",
        "      verbose=1,\n",
        "      shuffle=True\n",
        "  )"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "391/391 [==============================] - 45s 114ms/step - loss: 1.0238 - accuracy: 0.7256 - val_loss: 0.3759 - val_accuracy: 0.7581\n",
            "Epoch 2/50\n",
            "391/391 [==============================] - 44s 114ms/step - loss: 1.0336 - accuracy: 0.7214 - val_loss: 2.3786 - val_accuracy: 0.6519\n",
            "Epoch 3/50\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0492 - accuracy: 0.7240 - val_loss: 0.7616 - val_accuracy: 0.7212\n",
            "Epoch 4/50\n",
            "391/391 [==============================] - 44s 112ms/step - loss: 1.0659 - accuracy: 0.7237 - val_loss: 1.0546 - val_accuracy: 0.7348\n",
            "Epoch 5/50\n",
            "391/391 [==============================] - 44s 112ms/step - loss: 1.0152 - accuracy: 0.7260 - val_loss: 0.6241 - val_accuracy: 0.7624\n",
            "Epoch 6/50\n",
            "391/391 [==============================] - 44s 112ms/step - loss: 1.0124 - accuracy: 0.7269 - val_loss: 1.3179 - val_accuracy: 0.7283\n",
            "Epoch 7/50\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0537 - accuracy: 0.7252 - val_loss: 0.8410 - val_accuracy: 0.7613\n",
            "Epoch 8/50\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0297 - accuracy: 0.7239 - val_loss: 0.9039 - val_accuracy: 0.7041\n",
            "Epoch 9/50\n",
            "391/391 [==============================] - 45s 115ms/step - loss: 1.0428 - accuracy: 0.7278 - val_loss: 1.5944 - val_accuracy: 0.7181\n",
            "Epoch 10/50\n",
            "391/391 [==============================] - 45s 115ms/step - loss: 1.0677 - accuracy: 0.7235 - val_loss: 0.6639 - val_accuracy: 0.7226\n",
            "Epoch 11/50\n",
            "391/391 [==============================] - 45s 114ms/step - loss: 1.0099 - accuracy: 0.7285 - val_loss: 1.5296 - val_accuracy: 0.7119\n",
            "Epoch 12/50\n",
            "391/391 [==============================] - 44s 114ms/step - loss: 1.0625 - accuracy: 0.7256 - val_loss: 1.5140 - val_accuracy: 0.7410\n",
            "Epoch 13/50\n",
            "391/391 [==============================] - 45s 115ms/step - loss: 1.0349 - accuracy: 0.7308 - val_loss: 2.4820 - val_accuracy: 0.7466\n",
            "Epoch 14/50\n",
            "391/391 [==============================] - 45s 115ms/step - loss: 1.0340 - accuracy: 0.7280 - val_loss: 0.4154 - val_accuracy: 0.7547\n",
            "Epoch 15/50\n",
            "391/391 [==============================] - 45s 115ms/step - loss: 1.0309 - accuracy: 0.7283 - val_loss: 0.4771 - val_accuracy: 0.7402\n",
            "Epoch 16/50\n",
            "391/391 [==============================] - 45s 114ms/step - loss: 1.0023 - accuracy: 0.7300 - val_loss: 0.7062 - val_accuracy: 0.7742\n",
            "Epoch 17/50\n",
            "391/391 [==============================] - 45s 114ms/step - loss: 1.0232 - accuracy: 0.7310 - val_loss: 0.6143 - val_accuracy: 0.7695\n",
            "Epoch 18/50\n",
            "391/391 [==============================] - 45s 115ms/step - loss: 1.0293 - accuracy: 0.7284 - val_loss: 0.9682 - val_accuracy: 0.7381\n",
            "Epoch 19/50\n",
            "391/391 [==============================] - 45s 115ms/step - loss: 1.0049 - accuracy: 0.7291 - val_loss: 0.3025 - val_accuracy: 0.7456\n",
            "Epoch 20/50\n",
            "391/391 [==============================] - 45s 114ms/step - loss: 1.0265 - accuracy: 0.7292 - val_loss: 0.7314 - val_accuracy: 0.7487\n",
            "Epoch 21/50\n",
            "391/391 [==============================] - 44s 114ms/step - loss: 1.0447 - accuracy: 0.7294 - val_loss: 0.7307 - val_accuracy: 0.7524\n",
            "Epoch 22/50\n",
            "391/391 [==============================] - 45s 114ms/step - loss: 1.0627 - accuracy: 0.7287 - val_loss: 0.8064 - val_accuracy: 0.7460\n",
            "Epoch 23/50\n",
            "391/391 [==============================] - 44s 114ms/step - loss: 1.0510 - accuracy: 0.7275 - val_loss: 0.5682 - val_accuracy: 0.7592\n",
            "Epoch 24/50\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0047 - accuracy: 0.7320 - val_loss: 1.4945 - val_accuracy: 0.7605\n",
            "Epoch 25/50\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0158 - accuracy: 0.7294 - val_loss: 0.9106 - val_accuracy: 0.7521\n",
            "Epoch 26/50\n",
            "391/391 [==============================] - 45s 115ms/step - loss: 1.0449 - accuracy: 0.7278 - val_loss: 0.6615 - val_accuracy: 0.7560\n",
            "Epoch 27/50\n",
            "391/391 [==============================] - 45s 115ms/step - loss: 1.0436 - accuracy: 0.7265 - val_loss: 0.9130 - val_accuracy: 0.7570\n",
            "Epoch 28/50\n",
            "391/391 [==============================] - 45s 114ms/step - loss: 1.0522 - accuracy: 0.7274 - val_loss: 1.5177 - val_accuracy: 0.7436\n",
            "Epoch 29/50\n",
            "391/391 [==============================] - 45s 115ms/step - loss: 1.0097 - accuracy: 0.7308 - val_loss: 0.8539 - val_accuracy: 0.7332\n",
            "Epoch 30/50\n",
            "391/391 [==============================] - 45s 114ms/step - loss: 1.0439 - accuracy: 0.7295 - val_loss: 0.7068 - val_accuracy: 0.7492\n",
            "Epoch 31/50\n",
            "391/391 [==============================] - 45s 114ms/step - loss: 1.0506 - accuracy: 0.7277 - val_loss: 0.7142 - val_accuracy: 0.7481\n",
            "Epoch 32/50\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 0.9833 - accuracy: 0.7335 - val_loss: 0.8960 - val_accuracy: 0.7439\n",
            "Epoch 33/50\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0161 - accuracy: 0.7333 - val_loss: 0.9825 - val_accuracy: 0.7301\n",
            "Epoch 34/50\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0194 - accuracy: 0.7313 - val_loss: 0.8913 - val_accuracy: 0.7490\n",
            "Epoch 35/50\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0049 - accuracy: 0.7356 - val_loss: 2.0679 - val_accuracy: 0.7272\n",
            "Epoch 36/50\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0535 - accuracy: 0.7302 - val_loss: 0.2724 - val_accuracy: 0.7794\n",
            "Epoch 37/50\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0032 - accuracy: 0.7331 - val_loss: 1.1650 - val_accuracy: 0.7779\n",
            "Epoch 38/50\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0264 - accuracy: 0.7321 - val_loss: 0.2885 - val_accuracy: 0.7701\n",
            "Epoch 39/50\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0178 - accuracy: 0.7306 - val_loss: 0.6021 - val_accuracy: 0.7123\n",
            "Epoch 40/50\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0153 - accuracy: 0.7312 - val_loss: 0.8038 - val_accuracy: 0.7733\n",
            "Epoch 41/50\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0783 - accuracy: 0.7281 - val_loss: 0.6808 - val_accuracy: 0.7196\n",
            "Epoch 42/50\n",
            "391/391 [==============================] - 44s 114ms/step - loss: 1.0212 - accuracy: 0.7322 - val_loss: 1.2280 - val_accuracy: 0.7480\n",
            "Epoch 43/50\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0261 - accuracy: 0.7314 - val_loss: 0.3704 - val_accuracy: 0.7508\n",
            "Epoch 44/50\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0348 - accuracy: 0.7338 - val_loss: 0.8224 - val_accuracy: 0.7201\n",
            "Epoch 45/50\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0272 - accuracy: 0.7327 - val_loss: 0.7949 - val_accuracy: 0.7404\n",
            "Epoch 46/50\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0234 - accuracy: 0.7338 - val_loss: 0.8353 - val_accuracy: 0.7660\n",
            "Epoch 47/50\n",
            "391/391 [==============================] - 44s 114ms/step - loss: 1.0491 - accuracy: 0.7334 - val_loss: 1.0817 - val_accuracy: 0.7671\n",
            "Epoch 48/50\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0070 - accuracy: 0.7362 - val_loss: 1.8732 - val_accuracy: 0.7604\n",
            "Epoch 49/50\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0425 - accuracy: 0.7340 - val_loss: 0.9320 - val_accuracy: 0.7646\n",
            "Epoch 50/50\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 0.9997 - accuracy: 0.7335 - val_loss: 0.7570 - val_accuracy: 0.7712\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7m4hozajr6B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7429638e-6309-4b5b-9f08-ed46990483ba"
      },
      "source": [
        "# Train the model\n",
        "with tf.device('/device:GPU:0'):\n",
        "  model.fit(\n",
        "      training_set,\n",
        "      epochs=100,\n",
        "      validation_data=test_set,\n",
        "      verbose=1,\n",
        "      shuffle=True\n",
        "  )"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "391/391 [==============================] - 45s 115ms/step - loss: 1.0229 - accuracy: 0.7363 - val_loss: 1.1500 - val_accuracy: 0.7560\n",
            "Epoch 2/100\n",
            "391/391 [==============================] - 45s 115ms/step - loss: 1.0136 - accuracy: 0.7369 - val_loss: 0.7941 - val_accuracy: 0.7638\n",
            "Epoch 3/100\n",
            "391/391 [==============================] - 44s 114ms/step - loss: 1.0025 - accuracy: 0.7365 - val_loss: 1.0882 - val_accuracy: 0.7590\n",
            "Epoch 4/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0337 - accuracy: 0.7353 - val_loss: 0.8646 - val_accuracy: 0.7472\n",
            "Epoch 5/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0228 - accuracy: 0.7340 - val_loss: 0.7798 - val_accuracy: 0.7611\n",
            "Epoch 6/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0224 - accuracy: 0.7352 - val_loss: 0.4561 - val_accuracy: 0.7504\n",
            "Epoch 7/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0144 - accuracy: 0.7369 - val_loss: 0.3257 - val_accuracy: 0.7625\n",
            "Epoch 8/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0089 - accuracy: 0.7381 - val_loss: 1.1484 - val_accuracy: 0.7602\n",
            "Epoch 9/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0013 - accuracy: 0.7389 - val_loss: 1.0652 - val_accuracy: 0.7558\n",
            "Epoch 10/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0142 - accuracy: 0.7373 - val_loss: 1.2224 - val_accuracy: 0.7790\n",
            "Epoch 11/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0200 - accuracy: 0.7379 - val_loss: 0.1199 - val_accuracy: 0.7581\n",
            "Epoch 12/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 0.9970 - accuracy: 0.7365 - val_loss: 0.3496 - val_accuracy: 0.7679\n",
            "Epoch 13/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 0.9922 - accuracy: 0.7386 - val_loss: 1.3314 - val_accuracy: 0.7815\n",
            "Epoch 14/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0021 - accuracy: 0.7410 - val_loss: 0.9702 - val_accuracy: 0.7753\n",
            "Epoch 15/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0047 - accuracy: 0.7391 - val_loss: 0.8551 - val_accuracy: 0.7692\n",
            "Epoch 16/100\n",
            "391/391 [==============================] - 44s 114ms/step - loss: 1.0188 - accuracy: 0.7371 - val_loss: 0.2188 - val_accuracy: 0.7563\n",
            "Epoch 17/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0285 - accuracy: 0.7374 - val_loss: 0.9402 - val_accuracy: 0.7280\n",
            "Epoch 18/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 0.9812 - accuracy: 0.7393 - val_loss: 1.0808 - val_accuracy: 0.7590\n",
            "Epoch 19/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 0.9990 - accuracy: 0.7397 - val_loss: 1.5840 - val_accuracy: 0.7856\n",
            "Epoch 20/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0045 - accuracy: 0.7402 - val_loss: 0.2787 - val_accuracy: 0.7667\n",
            "Epoch 21/100\n",
            "391/391 [==============================] - 44s 114ms/step - loss: 0.9966 - accuracy: 0.7378 - val_loss: 0.3962 - val_accuracy: 0.7542\n",
            "Epoch 22/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 0.9851 - accuracy: 0.7403 - val_loss: 0.9148 - val_accuracy: 0.7479\n",
            "Epoch 23/100\n",
            "391/391 [==============================] - 44s 114ms/step - loss: 1.0063 - accuracy: 0.7382 - val_loss: 1.0175 - val_accuracy: 0.7665\n",
            "Epoch 24/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 0.9922 - accuracy: 0.7396 - val_loss: 1.7564 - val_accuracy: 0.7386\n",
            "Epoch 25/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0139 - accuracy: 0.7407 - val_loss: 1.0888 - val_accuracy: 0.7629\n",
            "Epoch 26/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0009 - accuracy: 0.7373 - val_loss: 0.8369 - val_accuracy: 0.7767\n",
            "Epoch 27/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0172 - accuracy: 0.7396 - val_loss: 0.5561 - val_accuracy: 0.7114\n",
            "Epoch 28/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 0.9994 - accuracy: 0.7432 - val_loss: 0.7300 - val_accuracy: 0.7476\n",
            "Epoch 29/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0235 - accuracy: 0.7393 - val_loss: 1.9108 - val_accuracy: 0.7658\n",
            "Epoch 30/100\n",
            "391/391 [==============================] - 44s 114ms/step - loss: 1.0056 - accuracy: 0.7398 - val_loss: 0.9843 - val_accuracy: 0.7725\n",
            "Epoch 31/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 0.9949 - accuracy: 0.7410 - val_loss: 0.9698 - val_accuracy: 0.7624\n",
            "Epoch 32/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 0.9902 - accuracy: 0.7438 - val_loss: 2.0642 - val_accuracy: 0.7673\n",
            "Epoch 33/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0138 - accuracy: 0.7411 - val_loss: 0.5918 - val_accuracy: 0.7529\n",
            "Epoch 34/100\n",
            "391/391 [==============================] - 44s 114ms/step - loss: 1.0058 - accuracy: 0.7402 - val_loss: 0.4681 - val_accuracy: 0.7017\n",
            "Epoch 35/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 0.9939 - accuracy: 0.7423 - val_loss: 0.4193 - val_accuracy: 0.7710\n",
            "Epoch 36/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0021 - accuracy: 0.7419 - val_loss: 0.4923 - val_accuracy: 0.7629\n",
            "Epoch 37/100\n",
            "391/391 [==============================] - 44s 114ms/step - loss: 0.9909 - accuracy: 0.7428 - val_loss: 1.1518 - val_accuracy: 0.7481\n",
            "Epoch 38/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 0.9916 - accuracy: 0.7426 - val_loss: 1.0738 - val_accuracy: 0.7790\n",
            "Epoch 39/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0138 - accuracy: 0.7396 - val_loss: 0.5470 - val_accuracy: 0.7522\n",
            "Epoch 40/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0336 - accuracy: 0.7397 - val_loss: 0.8219 - val_accuracy: 0.7017\n",
            "Epoch 41/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0163 - accuracy: 0.7413 - val_loss: 0.5209 - val_accuracy: 0.7494\n",
            "Epoch 42/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 0.9933 - accuracy: 0.7417 - val_loss: 1.8009 - val_accuracy: 0.7609\n",
            "Epoch 43/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0333 - accuracy: 0.7425 - val_loss: 0.9124 - val_accuracy: 0.7866\n",
            "Epoch 44/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0288 - accuracy: 0.7402 - val_loss: 1.2604 - val_accuracy: 0.7705\n",
            "Epoch 45/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 0.9970 - accuracy: 0.7392 - val_loss: 0.6446 - val_accuracy: 0.7200\n",
            "Epoch 46/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 0.9980 - accuracy: 0.7444 - val_loss: 1.1799 - val_accuracy: 0.7276\n",
            "Epoch 47/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 0.9893 - accuracy: 0.7445 - val_loss: 2.5848 - val_accuracy: 0.7720\n",
            "Epoch 48/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0199 - accuracy: 0.7412 - val_loss: 1.0925 - val_accuracy: 0.7508\n",
            "Epoch 49/100\n",
            "391/391 [==============================] - 44s 114ms/step - loss: 1.0195 - accuracy: 0.7432 - val_loss: 1.6701 - val_accuracy: 0.7153\n",
            "Epoch 50/100\n",
            "391/391 [==============================] - 44s 114ms/step - loss: 1.0168 - accuracy: 0.7424 - val_loss: 0.2822 - val_accuracy: 0.7779\n",
            "Epoch 51/100\n",
            "391/391 [==============================] - 45s 114ms/step - loss: 0.9858 - accuracy: 0.7429 - val_loss: 0.5633 - val_accuracy: 0.7785\n",
            "Epoch 52/100\n",
            "391/391 [==============================] - 45s 114ms/step - loss: 1.0097 - accuracy: 0.7431 - val_loss: 0.3520 - val_accuracy: 0.7474\n",
            "Epoch 53/100\n",
            "391/391 [==============================] - 45s 114ms/step - loss: 1.0061 - accuracy: 0.7414 - val_loss: 1.1663 - val_accuracy: 0.7794\n",
            "Epoch 54/100\n",
            "391/391 [==============================] - 45s 114ms/step - loss: 0.9978 - accuracy: 0.7420 - val_loss: 0.4309 - val_accuracy: 0.7501\n",
            "Epoch 55/100\n",
            "391/391 [==============================] - 45s 114ms/step - loss: 0.9756 - accuracy: 0.7459 - val_loss: 1.1120 - val_accuracy: 0.7673\n",
            "Epoch 56/100\n",
            "391/391 [==============================] - 44s 114ms/step - loss: 0.9852 - accuracy: 0.7434 - val_loss: 2.3589 - val_accuracy: 0.7185\n",
            "Epoch 57/100\n",
            "391/391 [==============================] - 44s 114ms/step - loss: 0.9803 - accuracy: 0.7468 - val_loss: 0.5599 - val_accuracy: 0.7870\n",
            "Epoch 58/100\n",
            "391/391 [==============================] - 45s 114ms/step - loss: 1.0017 - accuracy: 0.7447 - val_loss: 2.0041 - val_accuracy: 0.7711\n",
            "Epoch 59/100\n",
            "391/391 [==============================] - 45s 114ms/step - loss: 1.0165 - accuracy: 0.7436 - val_loss: 0.5665 - val_accuracy: 0.7771\n",
            "Epoch 60/100\n",
            "391/391 [==============================] - 44s 114ms/step - loss: 1.0050 - accuracy: 0.7434 - val_loss: 0.2784 - val_accuracy: 0.7630\n",
            "Epoch 61/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 0.9944 - accuracy: 0.7442 - val_loss: 0.5763 - val_accuracy: 0.7425\n",
            "Epoch 62/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 0.9882 - accuracy: 0.7447 - val_loss: 1.4479 - val_accuracy: 0.7580\n",
            "Epoch 63/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 0.9983 - accuracy: 0.7476 - val_loss: 0.9455 - val_accuracy: 0.7417\n",
            "Epoch 64/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0034 - accuracy: 0.7461 - val_loss: 0.8045 - val_accuracy: 0.7579\n",
            "Epoch 65/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0413 - accuracy: 0.7429 - val_loss: 0.7230 - val_accuracy: 0.7523\n",
            "Epoch 66/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 0.9854 - accuracy: 0.7465 - val_loss: 1.0981 - val_accuracy: 0.7586\n",
            "Epoch 67/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0217 - accuracy: 0.7426 - val_loss: 1.0961 - val_accuracy: 0.7586\n",
            "Epoch 68/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 0.9934 - accuracy: 0.7458 - val_loss: 2.1689 - val_accuracy: 0.7708\n",
            "Epoch 69/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 0.9977 - accuracy: 0.7458 - val_loss: 0.6577 - val_accuracy: 0.7886\n",
            "Epoch 70/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0031 - accuracy: 0.7458 - val_loss: 0.4772 - val_accuracy: 0.7615\n",
            "Epoch 71/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 0.9830 - accuracy: 0.7444 - val_loss: 2.3287 - val_accuracy: 0.7540\n",
            "Epoch 72/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0060 - accuracy: 0.7460 - val_loss: 0.7333 - val_accuracy: 0.7523\n",
            "Epoch 73/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 0.9902 - accuracy: 0.7482 - val_loss: 1.1304 - val_accuracy: 0.7693\n",
            "Epoch 74/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 0.9992 - accuracy: 0.7417 - val_loss: 1.6387 - val_accuracy: 0.7656\n",
            "Epoch 75/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 0.9940 - accuracy: 0.7454 - val_loss: 0.7076 - val_accuracy: 0.7453\n",
            "Epoch 76/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 0.9868 - accuracy: 0.7470 - val_loss: 1.4973 - val_accuracy: 0.7471\n",
            "Epoch 77/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0154 - accuracy: 0.7460 - val_loss: 1.6465 - val_accuracy: 0.7435\n",
            "Epoch 78/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0037 - accuracy: 0.7463 - val_loss: 2.9199 - val_accuracy: 0.7473\n",
            "Epoch 79/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0094 - accuracy: 0.7452 - val_loss: 1.6587 - val_accuracy: 0.7530\n",
            "Epoch 80/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0282 - accuracy: 0.7442 - val_loss: 1.0225 - val_accuracy: 0.7859\n",
            "Epoch 81/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 0.9917 - accuracy: 0.7487 - val_loss: 1.8306 - val_accuracy: 0.7720\n",
            "Epoch 82/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 0.9914 - accuracy: 0.7463 - val_loss: 1.9986 - val_accuracy: 0.7571\n",
            "Epoch 83/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 0.9822 - accuracy: 0.7484 - val_loss: 0.6548 - val_accuracy: 0.7372\n",
            "Epoch 84/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 0.9882 - accuracy: 0.7484 - val_loss: 3.2077 - val_accuracy: 0.7652\n",
            "Epoch 85/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0504 - accuracy: 0.7466 - val_loss: 0.9254 - val_accuracy: 0.7669\n",
            "Epoch 86/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0074 - accuracy: 0.7467 - val_loss: 0.8448 - val_accuracy: 0.7654\n",
            "Epoch 87/100\n",
            "391/391 [==============================] - 44s 112ms/step - loss: 0.9913 - accuracy: 0.7466 - val_loss: 0.5906 - val_accuracy: 0.7755\n",
            "Epoch 88/100\n",
            "391/391 [==============================] - 44s 112ms/step - loss: 0.9889 - accuracy: 0.7468 - val_loss: 0.9414 - val_accuracy: 0.7680\n",
            "Epoch 89/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 0.9945 - accuracy: 0.7490 - val_loss: 1.2093 - val_accuracy: 0.7779\n",
            "Epoch 90/100\n",
            "391/391 [==============================] - 44s 112ms/step - loss: 0.9878 - accuracy: 0.7475 - val_loss: 1.0338 - val_accuracy: 0.7610\n",
            "Epoch 91/100\n",
            "391/391 [==============================] - 44s 112ms/step - loss: 0.9831 - accuracy: 0.7498 - val_loss: 0.8587 - val_accuracy: 0.7259\n",
            "Epoch 92/100\n",
            "391/391 [==============================] - 44s 112ms/step - loss: 0.9955 - accuracy: 0.7470 - val_loss: 0.5067 - val_accuracy: 0.7813\n",
            "Epoch 93/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 0.9844 - accuracy: 0.7481 - val_loss: 0.3526 - val_accuracy: 0.7749\n",
            "Epoch 94/100\n",
            "391/391 [==============================] - 44s 112ms/step - loss: 1.0009 - accuracy: 0.7483 - val_loss: 0.7723 - val_accuracy: 0.7613\n",
            "Epoch 95/100\n",
            "391/391 [==============================] - 44s 112ms/step - loss: 1.0242 - accuracy: 0.7456 - val_loss: 1.4916 - val_accuracy: 0.7337\n",
            "Epoch 96/100\n",
            "391/391 [==============================] - 44s 112ms/step - loss: 1.0127 - accuracy: 0.7479 - val_loss: 1.5813 - val_accuracy: 0.7636\n",
            "Epoch 97/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 1.0093 - accuracy: 0.7476 - val_loss: 1.5995 - val_accuracy: 0.7715\n",
            "Epoch 98/100\n",
            "391/391 [==============================] - 44s 112ms/step - loss: 0.9817 - accuracy: 0.7509 - val_loss: 2.5412 - val_accuracy: 0.7676\n",
            "Epoch 99/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 0.9779 - accuracy: 0.7502 - val_loss: 1.2345 - val_accuracy: 0.7562\n",
            "Epoch 100/100\n",
            "391/391 [==============================] - 44s 113ms/step - loss: 0.9584 - accuracy: 0.7519 - val_loss: 1.0342 - val_accuracy: 0.7701\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfPwrdiQ2AuU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}